{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "initial_id",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2026-02-19T18:12:15.586834Z",
     "start_time": "2026-02-19T18:12:15.547112Z"
    },
    "collapsed": true
   },
   "outputs": [],
   "source": "import pandas as pd\nimport re\nimport numpy as np\n\n# =========================\n# 1) Load data\n# =========================\ndf = pd.read_csv('raw/corrected_transposed_JUNE24.csv')\n\n# =========================\n# 2) Section columns\n# =========================\nsection_cols = {\n    \"Intro\": \"intro_chordsTransposed\",\n    \"Verse\": \"verse_chordsTransposed\",\n    \"Pre-Chorus\": \"pre_chorus_chordsTransposed\",\n    \"Chorus\": \"chorus_chordsTransposed\",\n    \"Post-Chorus\": \"post_chorus_chordsTransposed\",\n    \"Bridge\": \"bridge_chordsTransposed\",\n    \"Outro\": \"outro_chordsTransposed\",\n}\n\n# =========================\n# 3) Pitch class mapping\n# =========================\nPC = {\n    \"C\":0,\"C#\":1,\"Db\":1,\"D\":2,\"D#\":3,\"Eb\":3,\"E\":4,\n    \"F\":5,\"F#\":6,\"Gb\":6,\"G\":7,\"G#\":8,\"Ab\":8,\n    \"A\":9,\"A#\":10,\"Bb\":10,\"B\":11\n}\n\nROMANS = [\"I\",\"II\",\"III\",\"IV\",\"V\",\"VI\",\"VII\"]\nMAJOR_SCALE = [0,2,4,5,7,9,11]\nMINOR_SCALE = [0,2,3,5,7,8,10]\n\n# =========================\n# 4) Utility functions\n# =========================\ndef split_chords(chord_string):\n    if pd.isna(chord_string) or str(chord_string).strip().upper() == \"NONE\":\n        return []\n    s = re.sub(r\"[,\\|;]\", \" \", str(chord_string))\n    s = s.replace(\"-\", \" \")\n    s = re.sub(r\"\\s+\", \" \", s).strip()\n    return s.split()\n\ndef parse_chord(sym):\n    m = re.match(r\"^([A-G])([#b]?)(.*)$\", sym)\n    if not m:\n        return None, \"maj\"\n    root = m.group(1) + (m.group(2) or \"\")\n    rest = m.group(3).lower()\n    quality = \"min\" if rest.startswith(\"m\") and not rest.startswith(\"maj\") else \"maj\"\n    return root, quality\n\ndef interval_to_roman(interval, mode, quality):\n    scale = MAJOR_SCALE if mode == \"major\" else MINOR_SCALE\n    diffs = [(abs(interval - deg), i) for i, deg in enumerate(scale)]\n    _, idx = min(diffs)\n    numeral = ROMANS[idx]\n    if quality == \"min\":\n        numeral = numeral.lower()\n    return numeral\n\ndef convert_to_roman(chords, key_root, key_mode):\n    if key_root not in PC:\n        return []\n    key_pc = PC[key_root]\n    romans = []\n    for sym in chords:\n        root, quality = parse_chord(sym)\n        if root not in PC:\n            continue\n        interval = (PC[root] - key_pc) % 12\n        romans.append(interval_to_roman(interval, key_mode, quality))\n    return romans\n\n# =========================\n# 5) Per-song key inference\n#    Priority: Chorus -> Intro -> any other section\n#    All sections of a song share the same key.\n# =========================\nKEY_PRIORITY = [\n    \"chorus_chordsTransposed\",\n    \"intro_chordsTransposed\",\n    \"verse_chordsTransposed\",\n    \"pre_chorus_chordsTransposed\",\n    \"post_chorus_chordsTransposed\",\n    \"bridge_chordsTransposed\",\n    \"outro_chordsTransposed\",\n]\n\ndef infer_song_key(row):\n    \"\"\"Return (key_root, key_mode) for a song row, checking sections by priority.\"\"\"\n    for col in KEY_PRIORITY:\n        if col not in row.index:\n            continue\n        chords = split_chords(row[col])\n        if not chords:\n            continue\n        root, quality = parse_chord(chords[0])\n        if root and root in PC:\n            mode = \"minor\" if quality == \"min\" else \"major\"\n            return root, mode\n    return None, None\n\n# =========================\n# 6) Build long-format dataset (all songs, all sections)\n# =========================\nrows = []\n\nfor _, r in df.iterrows():\n    song_key_root, song_key_mode = infer_song_key(r)\n    if song_key_root is None:\n        continue\n\n    for section_name, col in section_cols.items():\n        if col not in df.columns:\n            continue\n\n        chords = split_chords(r[col])\n        if not chords:\n            continue\n\n        roman_prog = convert_to_roman(chords, song_key_root, song_key_mode)\n        if not roman_prog:\n            continue\n\n        rows.append({\n            \"song_title\": r[\"song_title\"],\n            \"section\": section_name,\n            \"artist\": \"Taylor Swift\",\n            \"key\": song_key_root,\n            \"key_mode\": song_key_mode,\n            \"roman_progression\": roman_prog,\n            \"chord_progression_raw\": chords\n        })\n\nlong_df = pd.DataFrame(rows)\n\n# =========================\n# 7) Assign snippet IDs and export\n# =========================\nlong_df[\"snippet_id\"] = [\"TS_{:03d}\".format(i+1) for i in range(len(long_df))]\n\nlong_df[\"roman_progression\"] = long_df[\"roman_progression\"].apply(str)\nlong_df[\"chord_progression_raw\"] = long_df[\"chord_progression_raw\"].apply(str)\n\nout_df = long_df[[\n    \"snippet_id\",\n    \"song_title\",\n    \"section\",\n    \"artist\",\n    \"key\",\n    \"key_mode\",\n    \"roman_progression\",\n    \"chord_progression_raw\"\n]]\n\nout_df.to_csv(\"processed/toy_smashchords_tswift.csv\", index=False)\n\nprint(f\"Dataset created: {len(out_df)} snippets from {long_df['song_title'].nunique()} songs\")\nprint(out_df.head())\n"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "66a0c091c4c10a77",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2026-02-19T18:18:01.409970Z",
     "start_time": "2026-02-19T18:18:01.387333Z"
    }
   },
   "outputs": [],
   "source": "import pandas as pd\nimport ast\nfrom collections import Counter, defaultdict\n\n# =========================\n# 1) Load dataset\n# =========================\ntoy = pd.read_csv(\"processed/toy_smashchords_tswift.csv\")\n\ndef parse_roman_list(s):\n    if pd.isna(s):\n        return []\n    s = str(s).strip()\n    # Handle \"[I, V, vi]\" (no quotes)\n    if s.startswith(\"[\") and \"'\" not in s:\n        items = [x.strip() for x in s.strip(\"[]\").split(\",\") if x.strip()]\n        return items\n    # Handle \"['I','V','vi']\"\n    try:\n        return ast.literal_eval(s)\n    except Exception:\n        return [x.strip() for x in s.strip(\"[]\").split(\",\") if x.strip()]\n\ntoy[\"roman_list\"] = toy[\"roman_progression\"].apply(parse_roman_list)\n\n# =========================\n# 2) Count bigram transitions\n# =========================\ntransition_counts = Counter()\nstate_counts = Counter()\n\nfor prog in toy[\"roman_list\"]:\n    if not prog or len(prog) < 2:\n        continue\n    for a, b in zip(prog[:-1], prog[1:]):\n        transition_counts[(a, b)] += 1\n        state_counts[a] += 1\n\nstates = sorted(set([a for a, _ in transition_counts.keys()] + [b for _, b in transition_counts.keys()]))\n\n# =========================\n# 3) Transition probability matrix (Laplace smoothing)\n# =========================\nalpha = 1.0\nV = len(states)\n\nprob = defaultdict(dict)\nfor a in states:\n    denom = state_counts[a] + alpha * V\n    for b in states:\n        num = transition_counts.get((a, b), 0) + alpha\n        prob[a][b] = num / denom if denom > 0 else 1.0 / V\n\n# =========================\n# 4) Export counts & probs as CSV matrices\n# =========================\ncounts_mat = pd.DataFrame(0, index=states, columns=states, dtype=int)\nfor (a, b), c in transition_counts.items():\n    counts_mat.loc[a, b] = c\n\nprobs_mat = pd.DataFrame(0.0, index=states, columns=states, dtype=float)\nfor a in states:\n    for b in states:\n        probs_mat.loc[a, b] = prob[a][b]\n\ncounts_mat.to_csv(\"analysis/transition_counts.csv\")\nprobs_mat.to_csv(\"analysis/transition_probs.csv\")\n\nprint(\"Saved: analysis/transition_counts.csv, analysis/transition_probs.csv\")\nprint(\"Num states:\", V)\nprint(\"Top transitions:\", transition_counts.most_common(10))\n\n# =========================\n# 5) Markov transition score helper\n# =========================\ndef markov_score(from_prog, to_prog):\n    \"\"\"P(first_of_B | last_of_A)\"\"\"\n    if not from_prog or not to_prog:\n        return None\n    a = from_prog[-1]\n    b = to_prog[0]\n    if a not in prob or b not in prob[a]:\n        return 1.0 / V\n    return prob[a][b]\n\n# =========================\n# 6) Demo: score a pair of snippets\n# =========================\nA = toy.iloc[0][\"roman_list\"]\nB = toy.iloc[1][\"roman_list\"]\nprint(\"Example A:\", A)\nprint(\"Example B:\", B)\nprint(\"Markov score P(B0|A_last) =\", markov_score(A, B))\n"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3b3e3b7448258cf5",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2026-02-19T20:16:19.381863Z",
     "start_time": "2026-02-19T20:16:19.210920Z"
    }
   },
   "outputs": [],
   "source": "import pandas as pd\nimport ast\nimport math\nfrom collections import defaultdict\n\n# =========================\n# 0) Load dataset\n# =========================\ntoy = pd.read_csv(\"processed/toy_smashchords_tswift.csv\")\n\ndef parse_roman_list(s):\n    if pd.isna(s):\n        return []\n    s = str(s).strip()\n    if s.startswith(\"[\") and \"'\" not in s and '\"' not in s:\n        items = [x.strip() for x in s.strip(\"[]\").split(\",\") if x.strip()]\n        return items\n    try:\n        return ast.literal_eval(s)\n    except Exception:\n        return [x.strip() for x in s.strip(\"[]\").split(\",\") if x.strip()]\n\ntoy[\"roman_list\"] = toy[\"roman_progression\"].apply(parse_roman_list)\ntoy = toy[toy[\"roman_list\"].map(lambda x: isinstance(x, list) and len(x) > 0)].reset_index(drop=True)\n\n# =========================\n# 1) Normalize Roman symbols\n# =========================\ndef norm_roman(r):\n    r = str(r).strip()\n    r = r.replace(\"Â°\", \"\").replace(\"+\", \"\")\n    return r\n\ntoy[\"roman_list_norm\"] = toy[\"roman_list\"].apply(lambda xs: [norm_roman(x) for x in xs])\n\n# =========================\n# 2) Rotation-invariant (canonical) representation\n# =========================\ndef all_rotations(seq):\n    n = len(seq)\n    return [tuple(seq[i:]+seq[:i]) for i in range(n)]\n\ndef canonical_rotation(seq):\n    if not seq:\n        return tuple()\n    return min(all_rotations(list(seq)))\n\ntoy[\"canon_loop\"] = toy[\"roman_list_norm\"].apply(canonical_rotation)\n\ndef bigrams(seq):\n    if len(seq) < 2:\n        return set()\n    return set(zip(seq[:-1], seq[1:]))\n\ntoy[\"bigrams\"] = toy[\"roman_list_norm\"].apply(bigrams)\n\n# =========================\n# 3) Similarity metrics\n# =========================\ndef jaccard(a, b):\n    if not a and not b:\n        return 1.0\n    inter = len(a & b)\n    union = len(a | b)\n    return inter / union if union > 0 else 0.0\n\ndef loop_match_score(canonA, canonB):\n    return 1.0 if canonA == canonB and len(canonA) > 0 else 0.0\n\ndef length_compatibility(lenA, lenB):\n    d = abs(lenA - lenB)\n    return 1.0 / (1.0 + d)\n\n# =========================\n# 4) Key proximity (circle of fifths)\n# =========================\nCIRCLE = [\"C\",\"G\",\"D\",\"A\",\"E\",\"B\",\"F#\",\"C#\",\"Ab\",\"Eb\",\"Bb\",\"F\"]\nENHARMONIC = {\"Db\":\"C#\",\"Gb\":\"F#\",\"Cb\":\"B\",\"Fb\":\"E\",\"E#\":\"F\",\"B#\":\"C\",\"A#\":\"Bb\",\"D#\":\"Eb\",\"G#\":\"Ab\"}\n\ndef norm_key(k):\n    if k is None or pd.isna(k):\n        return None\n    k = str(k).strip()\n    return ENHARMONIC.get(k, k)\n\ndef circle_dist(k1, k2):\n    k1 = norm_key(k1); k2 = norm_key(k2)\n    if k1 not in CIRCLE or k2 not in CIRCLE:\n        return None\n    i = CIRCLE.index(k1); j = CIRCLE.index(k2)\n    d = abs(i - j)\n    return min(d, len(CIRCLE) - d)\n\ndef key_similarity(k1, k2):\n    d = circle_dist(k1, k2)\n    if d is None:\n        return 0.5\n    return 1.0 - d / 6.0\n\n# =========================\n# 5) Compatibility score\n# =========================\ndef compatibility_score(A, B, w_loop=0.45, w_bigram=0.45, w_len=0.10, w_key=0.00):\n    s_loop = loop_match_score(A[\"canon_loop\"], B[\"canon_loop\"])\n    s_big = jaccard(A[\"bigrams\"], B[\"bigrams\"])\n    s_len = length_compatibility(len(A[\"roman_list_norm\"]), len(B[\"roman_list_norm\"]))\n    s_key = key_similarity(A[\"key\"], B[\"key\"]) if w_key > 0 else 0.0\n    return (w_loop * s_loop) + (w_bigram * s_big) + (w_len * s_len) + (w_key * s_key)\n\n# =========================\n# 6) Top similar pairs\n# =========================\npairs = []\nn = len(toy)\nREQUIRE_DIFFERENT_SONGS = True\nW_KEY = 0.05\n\nfor i in range(n):\n    for j in range(n):\n        if i == j:\n            continue\n        A = toy.iloc[i]\n        B = toy.iloc[j]\n        if REQUIRE_DIFFERENT_SONGS and A[\"song_title\"] == B[\"song_title\"]:\n            continue\n        score = compatibility_score(A, B, w_key=W_KEY)\n        pairs.append({\n            \"from_snippet\": A[\"snippet_id\"],\n            \"from_song\": A[\"song_title\"],\n            \"from_section\": A[\"section\"],\n            \"from_key\": A[\"key\"],\n            \"from_prog\": A[\"roman_progression\"],\n            \"to_snippet\": B[\"snippet_id\"],\n            \"to_song\": B[\"song_title\"],\n            \"to_section\": B[\"section\"],\n            \"to_key\": B[\"key\"],\n            \"to_prog\": B[\"roman_progression\"],\n            \"score\": score\n        })\n\npairs_df = pd.DataFrame(pairs).sort_values(\"score\", ascending=False)\npairs_df.head(50).to_csv(\"analysis/top_pairs_medley.csv\", index=False)\nprint(\"Saved: analysis/top_pairs_medley.csv (top 50 pairs)\")\n\n# =========================\n# 7) Medley chain via beam search\n# =========================\ndef build_medley_chain(toy_df, K=5, beam_width=30, w_key=W_KEY):\n    M = 40\n    neighbors = defaultdict(list)\n    rows = [toy_df.iloc[i] for i in range(len(toy_df))]\n\n    for i, A in enumerate(rows):\n        scored = []\n        for j, B in enumerate(rows):\n            if i == j:\n                continue\n            if REQUIRE_DIFFERENT_SONGS and A[\"song_title\"] == B[\"song_title\"]:\n                continue\n            s = compatibility_score(A, B, w_key=w_key)\n            scored.append((s, j))\n        scored.sort(reverse=True, key=lambda x: x[0])\n        neighbors[i] = scored[:M]\n\n    beam = [(0.0, [i], {rows[i][\"song_title\"]}) for i in range(len(rows))]\n    beam.sort(reverse=True, key=lambda x: x[0])\n    beam = beam[:beam_width]\n\n    for step in range(1, K):\n        new_beam = []\n        for total, path, used_songs in beam:\n            last_i = path[-1]\n            for s, j in neighbors[last_i]:\n                B = rows[j]\n                if B[\"song_title\"] in used_songs:\n                    continue\n                new_beam.append((total + s, path + [j], used_songs | {B[\"song_title\"]}))\n        if not new_beam:\n            break\n        new_beam.sort(reverse=True, key=lambda x: x[0])\n        beam = new_beam[:beam_width]\n\n    best_total, best_path, _ = max(beam, key=lambda x: x[0])\n    chain_rows = []\n    for idx in best_path:\n        r = rows[idx]\n        chain_rows.append({\n            \"snippet_id\": r[\"snippet_id\"],\n            \"song_title\": r[\"song_title\"],\n            \"section\": r[\"section\"],\n            \"key\": r[\"key\"],\n            \"roman_progression\": r[\"roman_progression\"]\n        })\n    return best_total, pd.DataFrame(chain_rows)\n\nbest_score, best_chain = build_medley_chain(toy, K=5, beam_width=40, w_key=W_KEY)\nbest_chain.to_csv(\"analysis/best_medley_k5.csv\", index=False)\n\nprint(\"Saved: analysis/best_medley_k5.csv\")\nprint(\"Best chain total score:\", round(best_score, 4))\nprint(best_chain)\n"
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}