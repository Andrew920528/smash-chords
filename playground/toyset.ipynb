{
 "cells": [
  {
   "cell_type": "code",
   "id": "initial_id",
   "metadata": {
    "collapsed": true,
    "ExecuteTime": {
     "end_time": "2026-02-19T18:12:15.586834Z",
     "start_time": "2026-02-19T18:12:15.547112Z"
    }
   },
   "source": [
    "import pandas as pd\n",
    "import re\n",
    "import numpy as np\n",
    "\n",
    "# =========================\n",
    "# 1️⃣ 读取数据\n",
    "# =========================\n",
    "df = pd.read_csv('corrected_transposed_JUNE24.csv')\n",
    "\n",
    "# =========================\n",
    "# 2️⃣ Section 列\n",
    "# =========================\n",
    "section_cols = {\n",
    "    \"Intro\": \"intro_chordsTransposed\",\n",
    "    \"Verse\": \"verse_chordsTransposed\",\n",
    "    \"Pre-Chorus\": \"pre_chorus_chordsTransposed\",\n",
    "    \"Chorus\": \"chorus_chordsTransposed\",\n",
    "    \"Post-Chorus\": \"post_chorus_chordsTransposed\",\n",
    "    \"Bridge\": \"bridge_chordsTransposed\",\n",
    "    \"Outro\": \"outro_chordsTransposed\",\n",
    "}\n",
    "\n",
    "# =========================\n",
    "# 3️⃣ 音高映射\n",
    "# =========================\n",
    "PC = {\n",
    "    \"C\":0,\"C#\":1,\"Db\":1,\"D\":2,\"D#\":3,\"Eb\":3,\"E\":4,\n",
    "    \"F\":5,\"F#\":6,\"Gb\":6,\"G\":7,\"G#\":8,\"Ab\":8,\n",
    "    \"A\":9,\"A#\":10,\"Bb\":10,\"B\":11\n",
    "}\n",
    "\n",
    "ROMANS = [\"I\",\"II\",\"III\",\"IV\",\"V\",\"VI\",\"VII\"]\n",
    "MAJOR_SCALE = [0,2,4,5,7,9,11]\n",
    "MINOR_SCALE = [0,2,3,5,7,8,10]\n",
    "\n",
    "# =========================\n",
    "# 4️⃣ 工具函数\n",
    "# =========================\n",
    "def split_chords(chord_string):\n",
    "    if pd.isna(chord_string):\n",
    "        return []\n",
    "    s = re.sub(r\"[,\\|;]\", \" \", str(chord_string))\n",
    "    s = s.replace(\"-\", \" \")\n",
    "    s = re.sub(r\"\\s+\", \" \", s).strip()\n",
    "    return s.split()\n",
    "\n",
    "def parse_chord(sym):\n",
    "    m = re.match(r\"^([A-G])([#b]?)(.*)$\", sym)\n",
    "    if not m:\n",
    "        return None, \"maj\"\n",
    "    root = m.group(1) + (m.group(2) or \"\")\n",
    "    rest = m.group(3).lower()\n",
    "    quality = \"min\" if rest.startswith(\"m\") and not rest.startswith(\"maj\") else \"maj\"\n",
    "    return root, quality\n",
    "\n",
    "def infer_key(chords):\n",
    "    if not chords:\n",
    "        return None, None\n",
    "    root, quality = parse_chord(chords[0])\n",
    "    mode = \"minor\" if quality == \"min\" else \"major\"\n",
    "    return root, mode\n",
    "\n",
    "def interval_to_roman(interval, mode, quality):\n",
    "    scale = MAJOR_SCALE if mode == \"major\" else MINOR_SCALE\n",
    "    diffs = [(abs(interval - deg), i) for i, deg in enumerate(scale)]\n",
    "    _, idx = min(diffs)\n",
    "    numeral = ROMANS[idx]\n",
    "    if quality == \"min\":\n",
    "        numeral = numeral.lower()\n",
    "    return numeral\n",
    "\n",
    "def convert_to_roman(chords, key_root, key_mode):\n",
    "    if key_root not in PC:\n",
    "        return []\n",
    "    key_pc = PC[key_root]\n",
    "    romans = []\n",
    "    for sym in chords:\n",
    "        root, quality = parse_chord(sym)\n",
    "        if root not in PC:\n",
    "            continue\n",
    "        interval = (PC[root] - key_pc) % 12\n",
    "        romans.append(interval_to_roman(interval, key_mode, quality))\n",
    "    return romans\n",
    "\n",
    "# =========================\n",
    "# 5️⃣ 构建 long format\n",
    "# =========================\n",
    "rows = []\n",
    "\n",
    "for _, r in df.iterrows():\n",
    "    for section_name, col in section_cols.items():\n",
    "        if col not in df.columns:\n",
    "            continue\n",
    "\n",
    "        chords = split_chords(r[col])\n",
    "        if not chords:\n",
    "            continue\n",
    "\n",
    "        key_root, key_mode = infer_key(chords)\n",
    "        roman_prog = convert_to_roman(chords, key_root, key_mode)\n",
    "\n",
    "        if not roman_prog:\n",
    "            continue\n",
    "\n",
    "        rows.append({\n",
    "            \"song_title\": r[\"song_title\"],\n",
    "            \"section\": section_name,\n",
    "            \"artist\": \"Taylor Swift\",\n",
    "            \"key\": key_root,\n",
    "            \"key_mode\": key_mode,\n",
    "            \"roman_progression\": roman_prog,\n",
    "            \"chord_progression_raw\": chords\n",
    "        })\n",
    "\n",
    "long_df = pd.DataFrame(rows)\n",
    "\n",
    "# =========================\n",
    "# 6️⃣ 取 toy size = 50\n",
    "# =========================\n",
    "toy_df = long_df.head(50).copy()\n",
    "toy_df[\"snippet_id\"] = [\"TS_{:03d}\".format(i+1) for i in range(len(toy_df))]\n",
    "\n",
    "# list 转字符串\n",
    "toy_df[\"roman_progression\"] = toy_df[\"roman_progression\"].apply(lambda x: str(x))\n",
    "toy_df[\"chord_progression_raw\"] = toy_df[\"chord_progression_raw\"].apply(lambda x: str(x))\n",
    "\n",
    "# =========================\n",
    "# 7️⃣ 输出 toy CSV\n",
    "# =========================\n",
    "toy_df = toy_df[[\n",
    "    \"snippet_id\",\n",
    "    \"song_title\",\n",
    "    \"section\",\n",
    "    \"artist\",\n",
    "    \"key\",\n",
    "    \"key_mode\",\n",
    "    \"roman_progression\",\n",
    "    \"chord_progression_raw\"\n",
    "]]\n",
    "\n",
    "toy_df.to_csv(\"toy_smashchords_tswift_50.csv\", index=False)\n",
    "\n",
    "print(\"Toy dataset created successfully!\")\n"
   ],
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Toy dataset created successfully!\n"
     ]
    }
   ],
   "execution_count": 2
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2026-02-19T18:18:01.409970Z",
     "start_time": "2026-02-19T18:18:01.387333Z"
    }
   },
   "cell_type": "code",
   "source": [
    "import pandas as pd\n",
    "import ast\n",
    "from collections import Counter, defaultdict\n",
    "\n",
    "# =========================\n",
    "# 1) 读 toy dataset\n",
    "# =========================\n",
    "toy = pd.read_csv(\"toy_smashchords_tswift_50.csv\")\n",
    "\n",
    "# roman_progression 在 CSV 里通常是字符串，比如 \"[I, V, vi, IV]\"\n",
    "# 这里安全地转回 list\n",
    "def parse_roman_list(s):\n",
    "    if pd.isna(s):\n",
    "        return []\n",
    "    s = str(s).strip()\n",
    "    # 兼容两种写法：\"[I, V, vi]\" 或 \"['I','V','vi']\"\n",
    "    if s.startswith(\"[\") and \"'\" not in s:\n",
    "        # 把 I, V, vi 变成 'I','V','vi'\n",
    "        items = [x.strip() for x in s.strip(\"[]\").split(\",\") if x.strip()]\n",
    "        return items\n",
    "    # 如果本来就是 python list 字符串，直接 literal_eval\n",
    "    try:\n",
    "        return ast.literal_eval(s)\n",
    "    except Exception:\n",
    "        # fallback\n",
    "        return [x.strip() for x in s.strip(\"[]\").split(\",\") if x.strip()]\n",
    "\n",
    "toy[\"roman_list\"] = toy[\"roman_progression\"].apply(parse_roman_list)\n",
    "\n",
    "# =========================\n",
    "# 2) 统计转移次数 (bigram)\n",
    "# =========================\n",
    "transition_counts = Counter()\n",
    "state_counts = Counter()\n",
    "\n",
    "for prog in toy[\"roman_list\"]:\n",
    "    if not prog or len(prog) < 2:\n",
    "        continue\n",
    "    for a, b in zip(prog[:-1], prog[1:]):\n",
    "        transition_counts[(a, b)] += 1\n",
    "        state_counts[a] += 1\n",
    "\n",
    "# 所有出现过的“状态”\n",
    "states = sorted(set([a for a, _ in transition_counts.keys()] + [b for _, b in transition_counts.keys()]))\n",
    "\n",
    "# =========================\n",
    "# 3) 转成概率矩阵 (带 Laplace smoothing 防止 0 概率)\n",
    "# =========================\n",
    "alpha = 1.0  # smoothing strength (toy 阶段用 1 很稳)\n",
    "\n",
    "# P(b|a) = (count(a->b)+alpha) / (count(a)+alpha*|V|)\n",
    "V = len(states)\n",
    "\n",
    "prob = defaultdict(dict)\n",
    "for a in states:\n",
    "    denom = state_counts[a] + alpha * V\n",
    "    for b in states:\n",
    "        num = transition_counts.get((a, b), 0) + alpha\n",
    "        prob[a][b] = num / denom if denom > 0 else 1.0 / V\n",
    "\n",
    "# =========================\n",
    "# 4) 导出 counts & probs 为 CSV 矩阵\n",
    "# =========================\n",
    "counts_mat = pd.DataFrame(0, index=states, columns=states, dtype=int)\n",
    "for (a, b), c in transition_counts.items():\n",
    "    counts_mat.loc[a, b] = c\n",
    "\n",
    "probs_mat = pd.DataFrame(0.0, index=states, columns=states, dtype=float)\n",
    "for a in states:\n",
    "    for b in states:\n",
    "        probs_mat.loc[a, b] = prob[a][b]\n",
    "\n",
    "counts_mat.to_csv(\"transition_counts.csv\")\n",
    "probs_mat.to_csv(\"transition_probs.csv\")\n",
    "\n",
    "print(\"Saved: transition_counts.csv, transition_probs.csv\")\n",
    "print(\"Num states:\", V)\n",
    "print(\"Top transitions:\", transition_counts.most_common(10))\n",
    "\n",
    "# =========================\n",
    "# 5) 给 A->B transition 打分的函数\n",
    "#    (A 的最后一个 chord -> B 的第一个 chord)\n",
    "# =========================\n",
    "def markov_score(from_prog, to_prog):\n",
    "    \"\"\"\n",
    "    from_prog/to_prog: list[str]  (roman numerals list)\n",
    "    return: P(first_of_B | last_of_A)\n",
    "    \"\"\"\n",
    "    if not from_prog or not to_prog:\n",
    "        return None\n",
    "    a = from_prog[-1]\n",
    "    b = to_prog[0]\n",
    "    if a not in prob or b not in prob[a]:\n",
    "        # 如果没见过，给一个很小的默认值\n",
    "        return 1.0 / V\n",
    "    return prob[a][b]\n",
    "\n",
    "# =========================\n",
    "# 6) 示例：对 toy dataset 随便算几个 transition\n",
    "# =========================\n",
    "# 用前两条 snippet 做 demo\n",
    "A = toy.iloc[0][\"roman_list\"]\n",
    "B = toy.iloc[1][\"roman_list\"]\n",
    "print(\"Example A:\", A)\n",
    "print(\"Example B:\", B)\n",
    "print(\"Markov score P(B0|A_last) =\", markov_score(A, B))\n"
   ],
   "id": "66a0c091c4c10a77",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved: transition_counts.csv, transition_probs.csv\n",
      "Num states: 14\n",
      "Top transitions: [(('I', 'V'), 14), (('vi', 'IV'), 12), (('I', 'vi'), 12), (('V', 'V'), 11), (('V', 'II'), 10), (('IV', 'V'), 7), (('III', 'VII'), 6), (('II', 'iii'), 6), (('I', 'IV'), 6), (('i', 'III'), 5)]\n",
      "Example A: ['I', 'v', 'IV']\n",
      "Example B: ['i', 'VII', 'III', 'IV']\n",
      "Markov score P(B0|A_last) = 0.03333333333333333\n"
     ]
    }
   ],
   "execution_count": 4
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2026-02-19T20:16:19.381863Z",
     "start_time": "2026-02-19T20:16:19.210920Z"
    }
   },
   "cell_type": "code",
   "source": [
    "import pandas as pd\n",
    "import ast\n",
    "import math\n",
    "from collections import defaultdict\n",
    "\n",
    "# =========================\n",
    "# 0) Load toy dataset\n",
    "# =========================\n",
    "toy = pd.read_csv(\"toy_smashchords_tswift_50.csv\")\n",
    "\n",
    "def parse_roman_list(s):\n",
    "    if pd.isna(s):\n",
    "        return []\n",
    "    s = str(s).strip()\n",
    "    # Handle \"[I, V, vi, IV]\" (no quotes)\n",
    "    if s.startswith(\"[\") and \"'\" not in s and '\"' not in s:\n",
    "        items = [x.strip() for x in s.strip(\"[]\").split(\",\") if x.strip()]\n",
    "        return items\n",
    "    # Handle \"['I','V','vi','IV']\"\n",
    "    try:\n",
    "        return ast.literal_eval(s)\n",
    "    except Exception:\n",
    "        return [x.strip() for x in s.strip(\"[]\").split(\",\") if x.strip()]\n",
    "\n",
    "toy[\"roman_list\"] = toy[\"roman_progression\"].apply(parse_roman_list)\n",
    "\n",
    "# Filter out empty progressions\n",
    "toy = toy[toy[\"roman_list\"].map(lambda x: isinstance(x, list) and len(x) > 0)].reset_index(drop=True)\n",
    "\n",
    "# =========================\n",
    "# 1) Normalize Roman symbols (light cleanup)\n",
    "#    Keep b/#, keep case, strip °/+\n",
    "# =========================\n",
    "def norm_roman(r):\n",
    "    r = str(r).strip()\n",
    "    r = r.replace(\"°\", \"\").replace(\"+\", \"\")\n",
    "    return r\n",
    "\n",
    "toy[\"roman_list_norm\"] = toy[\"roman_list\"].apply(lambda xs: [norm_roman(x) for x in xs])\n",
    "\n",
    "# =========================\n",
    "# 2) Rotation-invariant representation for loop-like progressions\n",
    "#    Example: [I,V,vi,IV] and [vi,IV,I,V] should be close.\n",
    "#    We implement \"canonical rotation\": choose lexicographically smallest rotation.\n",
    "# =========================\n",
    "def all_rotations(seq):\n",
    "    n = len(seq)\n",
    "    return [tuple(seq[i:]+seq[:i]) for i in range(n)]\n",
    "\n",
    "def canonical_rotation(seq):\n",
    "    if not seq:\n",
    "        return tuple()\n",
    "    rots = all_rotations(list(seq))\n",
    "    return min(rots)\n",
    "\n",
    "toy[\"canon_loop\"] = toy[\"roman_list_norm\"].apply(lambda s: canonical_rotation(s))\n",
    "\n",
    "# Also create a \"set of bigrams\" as a robust similarity signal\n",
    "def bigrams(seq):\n",
    "    if len(seq) < 2:\n",
    "        return set()\n",
    "    return set(zip(seq[:-1], seq[1:]))\n",
    "\n",
    "toy[\"bigrams\"] = toy[\"roman_list_norm\"].apply(bigrams)\n",
    "\n",
    "# =========================\n",
    "# 3) Similarity metrics (Medley-style)\n",
    "#    Main idea: harmonic pattern similarity >> one-step transition probability\n",
    "#\n",
    "#    We'll combine:\n",
    "#      A) rotation similarity (exact match on canonical loop)  -> strong signal\n",
    "#      B) bigram Jaccard similarity                           -> robust for different lengths\n",
    "#      C) optional: length compatibility penalty\n",
    "# =========================\n",
    "def jaccard(a, b):\n",
    "    if not a and not b:\n",
    "        return 1.0\n",
    "    inter = len(a & b)\n",
    "    union = len(a | b)\n",
    "    return inter / union if union > 0 else 0.0\n",
    "\n",
    "def loop_match_score(canonA, canonB):\n",
    "    # exact canonical loop match\n",
    "    return 1.0 if canonA == canonB and len(canonA) > 0 else 0.0\n",
    "\n",
    "def length_compatibility(lenA, lenB):\n",
    "    # 1.0 when equal length, decays with difference\n",
    "    d = abs(lenA - lenB)\n",
    "    return 1.0 / (1.0 + d)\n",
    "\n",
    "# =========================\n",
    "# 4) Optional key proximity cost (small weight)\n",
    "#    For medley, you can often transpose, so keep weight low or turn off.\n",
    "# =========================\n",
    "CIRCLE = [\"C\",\"G\",\"D\",\"A\",\"E\",\"B\",\"F#\",\"C#\",\"Ab\",\"Eb\",\"Bb\",\"F\"]\n",
    "ENHARMONIC = {\"Db\":\"C#\",\"Gb\":\"F#\",\"Cb\":\"B\",\"Fb\":\"E\",\"E#\":\"F\",\"B#\":\"C\",\"A#\":\"Bb\",\"D#\":\"Eb\",\"G#\":\"Ab\"}\n",
    "\n",
    "def norm_key(k):\n",
    "    if k is None or pd.isna(k):\n",
    "        return None\n",
    "    k = str(k).strip()\n",
    "    return ENHARMONIC.get(k, k)\n",
    "\n",
    "def circle_dist(k1, k2):\n",
    "    k1 = norm_key(k1); k2 = norm_key(k2)\n",
    "    if k1 not in CIRCLE or k2 not in CIRCLE:\n",
    "        return None\n",
    "    i = CIRCLE.index(k1); j = CIRCLE.index(k2)\n",
    "    d = abs(i - j)\n",
    "    return min(d, len(CIRCLE) - d)\n",
    "\n",
    "def key_similarity(k1, k2):\n",
    "    \"\"\"\n",
    "    Convert circle distance to similarity in [0,1]\n",
    "    0 steps -> 1.0, 6 steps -> 0.0\n",
    "    \"\"\"\n",
    "    d = circle_dist(k1, k2)\n",
    "    if d is None:\n",
    "        return 0.5\n",
    "    return 1.0 - d / 6.0\n",
    "\n",
    "# =========================\n",
    "# 5) Final compatibility score\n",
    "#    Score(A,B) in [0, ~something], higher = better match for medley stitching.\n",
    "#    You can tune weights.\n",
    "# =========================\n",
    "def compatibility_score(A, B, w_loop=0.45, w_bigram=0.45, w_len=0.10, w_key=0.00):\n",
    "    # Main: harmonic pattern similarity\n",
    "    s_loop = loop_match_score(A[\"canon_loop\"], B[\"canon_loop\"])\n",
    "    s_big = jaccard(A[\"bigrams\"], B[\"bigrams\"])\n",
    "    s_len = length_compatibility(len(A[\"roman_list_norm\"]), len(B[\"roman_list_norm\"]))\n",
    "    s_key = key_similarity(A[\"key\"], B[\"key\"]) if w_key > 0 else 0.0\n",
    "\n",
    "    return (w_loop * s_loop) + (w_bigram * s_big) + (w_len * s_len) + (w_key * s_key)\n",
    "\n",
    "# =========================\n",
    "# 6) Compute top similar pairs (for inspection / demo)\n",
    "# =========================\n",
    "pairs = []\n",
    "n = len(toy)\n",
    "\n",
    "# Change this if you want to allow same song snippets:\n",
    "REQUIRE_DIFFERENT_SONGS = True\n",
    "\n",
    "# Set w_key small if you want key proximity as a tie-breaker (e.g., 0.05)\n",
    "W_KEY = 0.05  # set to 0.0 if you want to ignore key entirely\n",
    "\n",
    "for i in range(n):\n",
    "    for j in range(n):\n",
    "        if i == j:\n",
    "            continue\n",
    "        A = toy.iloc[i]\n",
    "        B = toy.iloc[j]\n",
    "        if REQUIRE_DIFFERENT_SONGS and A[\"song_title\"] == B[\"song_title\"]:\n",
    "            continue\n",
    "\n",
    "        score = compatibility_score(A, B, w_key=W_KEY)\n",
    "        pairs.append({\n",
    "            \"from_snippet\": A[\"snippet_id\"],\n",
    "            \"from_song\": A[\"song_title\"],\n",
    "            \"from_section\": A[\"section\"],\n",
    "            \"from_key\": A[\"key\"],\n",
    "            \"from_prog\": A[\"roman_progression\"],\n",
    "            \"to_snippet\": B[\"snippet_id\"],\n",
    "            \"to_song\": B[\"song_title\"],\n",
    "            \"to_section\": B[\"section\"],\n",
    "            \"to_key\": B[\"key\"],\n",
    "            \"to_prog\": B[\"roman_progression\"],\n",
    "            \"score\": score\n",
    "        })\n",
    "\n",
    "pairs_df = pd.DataFrame(pairs).sort_values(\"score\", ascending=False)\n",
    "pairs_df.head(50).to_csv(\"top_pairs_medley.csv\", index=False)\n",
    "print(\"Saved: top_pairs_medley.csv (top 50 pairs)\")\n",
    "\n",
    "# =========================\n",
    "# 7) Build a K-snippet medley chain (K=5 default)\n",
    "#    Use beam search to avoid getting stuck.\n",
    "#    Constraint: all songs unique (typical medley).\n",
    "# =========================\n",
    "def build_medley_chain(toy_df, K=5, beam_width=30, w_key=W_KEY):\n",
    "    # Precompute best outgoing neighbors for each snippet to speed up\n",
    "    # We'll keep top M neighbors per snippet\n",
    "    M = 40\n",
    "    neighbors = defaultdict(list)\n",
    "\n",
    "    # indexable rows\n",
    "    rows = [toy_df.iloc[i] for i in range(len(toy_df))]\n",
    "\n",
    "    for i, A in enumerate(rows):\n",
    "        scored = []\n",
    "        for j, B in enumerate(rows):\n",
    "            if i == j:\n",
    "                continue\n",
    "            if REQUIRE_DIFFERENT_SONGS and A[\"song_title\"] == B[\"song_title\"]:\n",
    "                continue\n",
    "            s = compatibility_score(A, B, w_key=w_key)\n",
    "            scored.append((s, j))\n",
    "        scored.sort(reverse=True, key=lambda x: x[0])\n",
    "        neighbors[i] = scored[:M]\n",
    "\n",
    "    # Beam search state: (total_score, path_indices, used_song_titles)\n",
    "    beam = []\n",
    "    # initialize beam with each snippet as start\n",
    "    for i, A in enumerate(rows):\n",
    "        beam.append((0.0, [i], {A[\"song_title\"]}))\n",
    "    # keep top starts\n",
    "    beam.sort(reverse=True, key=lambda x: x[0])\n",
    "    beam = beam[:beam_width]\n",
    "\n",
    "    for step in range(1, K):\n",
    "        new_beam = []\n",
    "        for total, path, used_songs in beam:\n",
    "            last_i = path[-1]\n",
    "            for s, j in neighbors[last_i]:\n",
    "                B = rows[j]\n",
    "                if B[\"song_title\"] in used_songs:\n",
    "                    continue  # enforce unique songs in medley\n",
    "                new_total = total + s\n",
    "                new_path = path + [j]\n",
    "                new_used = set(used_songs)\n",
    "                new_used.add(B[\"song_title\"])\n",
    "                new_beam.append((new_total, new_path, new_used))\n",
    "\n",
    "        if not new_beam:\n",
    "            break\n",
    "\n",
    "        new_beam.sort(reverse=True, key=lambda x: x[0])\n",
    "        beam = new_beam[:beam_width]\n",
    "\n",
    "    best = max(beam, key=lambda x: x[0])\n",
    "    best_total, best_path, _ = best\n",
    "\n",
    "    # Convert to readable output\n",
    "    chain_rows = []\n",
    "    for idx in best_path:\n",
    "        r = rows[idx]\n",
    "        chain_rows.append({\n",
    "            \"snippet_id\": r[\"snippet_id\"],\n",
    "            \"song_title\": r[\"song_title\"],\n",
    "            \"section\": r[\"section\"],\n",
    "            \"key\": r[\"key\"],\n",
    "            \"roman_progression\": r[\"roman_progression\"]\n",
    "        })\n",
    "\n",
    "    out = pd.DataFrame(chain_rows)\n",
    "    return best_total, out\n",
    "\n",
    "best_score, best_chain = build_medley_chain(toy, K=5, beam_width=40, w_key=W_KEY)\n",
    "best_chain.to_csv(\"best_medley_k5.csv\", index=False)\n",
    "\n",
    "print(\"Saved: best_medley_k5.csv\")\n",
    "print(\"Best chain total score:\", round(best_score, 4))\n",
    "print(best_chain)\n"
   ],
   "id": "3b3e3b7448258cf5",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved: top_pairs_medley.csv (top 50 pairs)\n",
      "Saved: best_medley_k5.csv\n",
      "Best chain total score: 1.8467\n",
      "  snippet_id                                     song_title section key  \\\n",
      "0     TS_014                   bad blood (taylor's version)   Verse   C   \n",
      "1     TS_010                                  midnight rain  Bridge   F   \n",
      "2     TS_044                                 stay beautiful   Verse  C#   \n",
      "3     TS_041                     fifteen (taylor's version)  Bridge   C   \n",
      "4     TS_017  florida!!! (featuring florence + the machine)   Verse   F   \n",
      "\n",
      "               roman_progression  \n",
      "0        ['I', 'V', 'II', 'iii']  \n",
      "1        ['I', 'V', 'II', 'iii']  \n",
      "2  ['I', 'II', 'V', 'II', 'iii']  \n",
      "3  ['I', 'iii', 'II', 'V', 'II']  \n",
      "4             ['I', 'iii', 'II']  \n"
     ]
    }
   ],
   "execution_count": 8
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
